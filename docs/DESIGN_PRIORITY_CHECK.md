# チケット/タスク優先度の齟齬チェック（設計メモ）

## 目的
- チケットとタスクの優先度が内容に対して乖離していないかを早期に検知し、人が確認できる形で提示する。
- 自動変更は行わず、**提案と警告のみ**を行う（人が最終判断）。

## 想定入力
- チケット: 件名、本文、種別、優先度、SLA期限、最新コメント
- タスク: 件名、説明、優先度、期限、ステータス、担当
- （任意）影響範囲/緊急度のメタ情報

## 2段階チェック（推奨）

### 1) ルールベース（軽量・即時）
明確な違和感を先に検知する。
- 例: チケットが P1 なのにタスクが全て「低」かつ「期限なし」
- 例: チケットが incident なのにタスクが「未着手」かつ「低」
- 例: SLA期限が近いのにタスク優先度が「低」

### 2) LLMベース（内容整合性の判断）
ルールで拾えない曖昧な乖離を検知する。
- 入力: チケット概要＋タスク一覧の要約
- 出力（JSON想定）:
  - `risk_score`（0.0〜1.0）
  - `reason`（簡潔な根拠）
  - `suggested_priority`（チケット/タスクそれぞれの提案）
  - `needs_review`（true/false）

## ガードレール
- **自動変更は禁止**（UI上の提案に留める）。
- 根拠を必須にして、人が判断できる形にする。
- **過剰な通知を避ける**ため、閾値（例: `risk_score >= 0.7`）で絞り込む。

## UI表示案
- チケット詳細に「優先度整合性: OK / 要確認」を表示
- 「要確認」時は理由と提案を展開表示

## 学習/改善
- ユーザーが「正しい/誤検知」をフィードバック可能にする
- フィードバックは評価ログとして保存し、将来の改善に利用

## RAG を使うか？OpenAI/Google の API エンドポイントを活用するか？
前提: **RAG は LLM API の上に構築する**。ここでは以下の3案を比較する。

### A. 自前 RAG（ベクトルDB + embeddings + LLM）
**特徴**
- 自社データを埋め込み検索で取り込み、プロンプトに根拠を注入する方式。
- 使う LLM は OpenAI/Google いずれでも可。

**メリット/デメリット（観点別）**
- コスト
  - ✅ LLM への入力を必要最小限にでき、長文の丸投げより安くなる可能性
  - ❌ embeddings 作成・ベクトルDB保管・検索実行の追加コストが発生
- 速度
  - ✅ キャッシュ/事前計算で高速化しやすい
  - ❌ 検索ステップが増えるため、純粋な LLM 呼び出しより遅くなる
- 精度
  - ✅ 最新/社内固有の情報に強く、根拠付き応答になりやすい
  - ❌ 検索品質（クエリ設計/埋め込み/データ整備）に精度が依存
- 実装難易度
  - ✅ ベンダーロックインは相対的に低い（LLM切替が容易）
  - ❌ インデックス構築/更新/監視が必要で運用コストが高い

### B. ベンダー内蔵の検索/グラウンディング（OpenAI / Gemini）
**特徴**
- OpenAI の Responses API の **File Search / Web Search** などの内蔵ツールを利用。
- Gemini API の **File Search / Google Search grounding** を利用。
- 料金体系は **ツール利用の追加課金** がある（例: OpenAIはFile Searchのストレージ/ツール呼び出し、GoogleはFile Searchの埋め込みやGroundingのリクエスト課金）。

**メリット/デメリット（観点別）**
- コスト
  - ✅ インフラを自前で持たない分、固定費が小さい
  - ❌ ツール呼び出し・ストレージ等の **追加課金** が発生（ベンダー価格表に依存）
- 速度
  - ✅ 実装は簡単で試行が速い
  - ❌ ツール呼び出しが入る分、レイテンシは増える
- 精度
  - ✅ 公式の検索/埋め込み基盤を使える
  - ❌ 取得範囲/ランキングの自由度が低く、調整余地が小さい
- 実装難易度
  - ✅ API 設定のみで短期導入が可能
  - ❌ ベンダー機能に依存しやすく、後の移行が難しくなる

### C. 素の LLM API（RAG なし）
**特徴**
- OpenAI Responses API / Gemini API の生成エンドポイントをそのまま使う。

**メリット/デメリット（観点別）**
- コスト
  - ✅ 追加の検索コストがない
  - ❌ 長文の再送でトークンコストが増えやすい
- 速度
  - ✅ 追加ステップがなく最速
  - ❌ 長文プロンプトは遅くなりがち
- 精度
  - ✅ 一般知識は強い
  - ❌ 社内/最新情報の正確性は低くなりやすい
- 実装難易度
  - ✅ 最も簡単（API呼び出しのみ）
  - ❌ 誤り検知/根拠提示が難しい

### 参考（公式）
- OpenAI: Responses API / ツール（File Search, Web Search）と価格表
  - https://platform.openai.com/docs/guides/tools/file-search
  - https://platform.openai.com/docs/pricing
- Google: Gemini API（生成/ストリーミング/バッチ/埋め込み）と価格表、Grounding / File Search
  - https://ai.google.dev/gemini-api/docs/grounding
  - https://ai.google.dev/pricing

## 実装メモ（将来）
- LLM呼び出しは `Req` を使用
- 入力は **最小限**にまとめてコスト最適化
- 監査性のため、判断ログを別イベントとして保存（将来の監査・再現用）
